---
title: "ST 558 - Homework 5"
author: "Kyra Kapsaskis"
format: html
editor: visual
---

## Task 1

Open-ended questions

## Task 2: Fitting Models
```{r}
install.packages("randomForest")
```

```{r}
# libraries

library(caret)
library(tidyr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(Hmisc)
library(randomForest)
```

### Quick EDA/Data Preparation

------------------------------------------------------------------------

### 1.) understand the data better

```{r}

# reading in the data and reading about the data 
# (https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)

heart_data <- read.csv("https://www4.stat.ncsu.edu/~online/datasets/heart.csv")
```

```{r}
# checking for missing data and summarizing the data

describe(heart_data)

# there is a column here that gives you the number of missing data points

# Looks like we're good!

```

```{r}

# summary statistics

summary(heart_data)
```

```{r}
# this is giving us summary stats for when heart disease is 0 and 1

lapply(split(heart_data, heart_data$HeartDisease), describe)
```

```{r}
# cross tab - using lapply to create many different contingency tables

lapply(heart_data[, c("Sex", "ChestPainType", "RestingECG", "ExerciseAngina")], FUN = function(x) table(heart_data$HeartDisease, x))

```

```{r}

# summarizing the numerical variables

heart_data |>
  group_by(HeartDisease) |>
  dplyr::summarize(across(where(is.numeric),
                   list("mean" = ~ mean(.x, na.rm = TRUE), "median" = ~ median(.x, na.rm = TRUE)), 
                   .names = "{.fn}_{.col}"))
```

------------------------------------------------------------------------
### 2.) creating a new variable

```{r}
# seeing what the structure of the data is currently
str(heart_data)
```

```{r}
# figuring out how to use the factor function
help(factor)
```

```{r}
# create a new variable that is a factor version of the HeartDisease variable (if needed)
# also drop original columns

heart_data <- heart_data |>
  mutate(HeartDisease_factor = factor(HeartDisease, labels = c("Normal", "heart disease"))) |>
  select(-any_of(c("ST_Slope", "HeartDisease")))
       

```


------------------------------------------------------------------------
### 3.) create dummy variables to prepare for kNN

```{r}
# Create dummy columns for the three categorical predictors using dummyVars() and predict(). 
 

help(dummyVars)

```

```{r}
# making our character variables factor variables, so we can make dummy columns

heart_data[,c("Sex", "ChestPainType", "RestingECG")] = lapply(heart_data[,c("Sex", "ChestPainType", "RestingECG")],factor) 
```

```{r}
# create new variable with names of important factors in it

imp_factors = c("Sex", "ChestPainType", "RestingECG")
```

```{r}
new_dummy_cols = dummyVars(~Sex + ChestPainType + RestingECG,heart_data,fullRank = T)
heart_data=cbind(heart_data,predict(new_dummy_cols, heart_data[,imp_factors]))
```


## Split your Data

```{r}
# set a seed for reproducibility
set.seed(10)

#indices to split on
train <- sample(1:nrow(heart_data), size = nrow(heart_data)*0.8)
test <- dplyr::setdiff(1:nrow(heart_data), train)

#subset
heartTrain <- heart_data[train, ]
heartTest <- heart_data[test, ]
```

## kNN

```{r}
help(trainControl)
```

```{r}
# defining cv arguments

cv_settings <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

```

```{r}
help(train)
```

```{r}
tune_grid <- expand.grid(k = 1:40)
```


```{r}

# need to add TuneGrid

my_knn <- train(HeartDisease_factor ~., data = heartTrain, method = "knn",
  trControl = cv_settings,
  preProcess = c("center", "scale"),
  tuneGrid = tune_grid)
```

```{r}
my_knn
```
```{r}
help(predict)
```

```{r}
knn_predict <- predict(my_knn, heartTest)
```

```{r}
summary(knn_predict)
```


```{r}
# first want to set up a cross validation function - training set will also be split into its own little training/testing set (k fold and then averaging across all combinations). test set is reserved for after model is fit. should not be included in model fitting


# remember not to include both versions of variables
# data2 = data[,c("HeartDisease_factor","Sex.M","ChestPainType.ATA",...)]
# HeartDisease_factor ~ . , data
```

```{r}
# confusion matrix

confusionMatrix(knn_predict, heartTest$HeartDisease_factor)
```


Logistic Regression

```{r}
# R will do the dummy coding for you so you can use the regular categorical variables, not dummy. use factor variables

#glmFit <- glm(good ~ yards, 
#             data = FGData, 
#              family = "binomial")

my_logreg_1 <- train(HeartDisease_factor ~ ChestPainType.ATA + RestingECG.ST, data = heartTrain, method = "glm", family = "binomial", trControl = cv_settings)

```

```{r}
my_logreg_1
```

```{r}
log1_predict <- predict(my_logreg_1, heartTest)
```

```{r}
log1_predict
```
```{r}
summary(log1_predict)
```


```{r}
my_logreg_2 <- train(HeartDisease_factor ~ Age + Cholesterol, data = heartTrain, method = "glm", family = "binomial", trControl = cv_settings)
```

```{r}
my_logreg_2
```

```{r}
log2_predict <- predict(my_logreg_2, heartTest)
```

```{r}
summary(log2_predict)
```



```{r}
my_logreg_3 <- train(HeartDisease_factor ~ MaxHR + RestingBP, data = heartTrain, method = "glm", family = "binomial", trControl = cv_settings)
```

```{r}
log3_predict <- predict(my_logreg_3, heartTest)
```

```{r}
summary(log3_predict)
```

```{r}

confusionMatrix(log1_predict, heartTest$HeartDisease_factor)
confusionMatrix(log2_predict, heartTest$HeartDisease_factor)
confusionMatrix(log3_predict, heartTest$HeartDisease_factor)

```


## the best logistic regression model was the one with Maximum Heart Rate and Resting Blood Pressure



# Tree Models

```{r}
library(tidyverse)
library(haven)
library(knitr)
library(rgl)
library(tree)
```

## Classification Tree
```{r}
my_tree <- train(HeartDisease_factor ~ ChestPainType, 
                data = heartTrain, method = "rpart", trControl = cv_settings,  tuneGrid = expand.grid(cp = seq(0, 0.1, 0.001)))
my_tree
```
```{r}
plot(my_tree)
```
```{r}
tree_predict <- predict(my_tree, heartTest)
```

```{r}
summary(tree_predict)
```


```{r}
confusionMatrix(tree_predict, heartTest$HeartDisease_factor)
```

## Random Forest Model

```{r}
install.packages("randomForest")
```


```{r}
my_rf <- train(HeartDisease_factor ~ ChestPainType, 
                data = heartTrain, method = "rf", trControl = cv_settings,  tuneGrid = expand.grid(mtry = seq(1, 4, 1)))
my_rf
```

```{r}
rf_predict <- predict(my_rf, heartTest)
```

```{r}
summary(rf_predict)
```

```{r}
confusionMatrix(rf_predict, heartTest$HeartDisease_factor)
```



```{r}
# Boosted Tree Model

library(gbm)
```


```{r}
tuning_params <- expand.grid(n.trees = c(25, 50, 100, 200), interaction.depth = c(1, 2, 3), shrinkage = 0.1, n.minobsinnode = 10)

```


```{r}
my_boost <- train(HeartDisease_factor ~ Cholesterol + RestingBP + ChestPainType, data = heartTrain, method = "gbm", trControl = cv_settings, tuneGrid = tuning_params, verbose = FALSE)

```

```{r}
my_boost
```

```{r}
boost_predict <- predict(my_boost, heartTest)
```

```{r}
summary(boost_predict)
```

```{r}
boost_predict
```


```{r}
confusionMatrix(boost_predict, heartTest$HeartDisease_factor)
```


```{r}
knn_accuracy <- confusionMatrix(knn_predict, heartTest$HeartDisease_factor) 
log1_accuracy <- confusionMatrix(log1_predict, heartTest$HeartDisease_factor)
log2_accuracy <- confusionMatrix(log2_predict, heartTest$HeartDisease_factor)
log3_accuracy <- confusionMatrix(log3_predict, heartTest$HeartDisease_factor)
tree_accuracy <- confusionMatrix(tree_predict, heartTest$HeartDisease_factor)
rf_accuracy <- confusionMatrix(rf_predict, heartTest$HeartDisease_factor)
boost_accuracy <- confusionMatrix(boost_predict, heartTest$HeartDisease_factor)
```


```{r}

# Which model is the best

confusion_final <- c(knn_accuracy, log1_accuracy, log2_accuracy, log3_accuracy, tree_accuracy, rf_accuracy, boost_accuracy)
```

```{r}
confusion_final
```

# ChestPainType was the best predictor and in the Tree Model and RF Model

```{r}

# random notes

# also create a new dataset with cbind of a version of the predictors that only use the dummy columns
# doesn't handle categorical variables well
# could PROBABLY use same dataset EXCEPT it's possible it will want heart disease as a nonfactor


```

